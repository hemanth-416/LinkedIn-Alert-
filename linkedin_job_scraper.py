import os
import smtplib
from email.mime.text import MIMEText
import requests
from requests.adapters import HTTPAdapter, Retry
from bs4 import BeautifulSoup
from flask import Flask
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
from io import StringIO
from datetime import datetime, timezone  # timezone-aware

app = Flask(__name__)

# -------------------------
# Tuning knobs to control egress
# -------------------------
MAX_PAGES = int(os.getenv("MAX_PAGES", 2))                  # pages per query (0, 25, ...)
PER_RUN_LOCATIONS = int(os.getenv("PER_RUN_LOCATIONS", 6))  # metros per run
TIME_WINDOW = os.getenv("TIME_WINDOW", "r3600")             # r3600=1h, r86400=24h, r604800=7d
ENFORCE_COUNTRY = os.getenv("ENFORCE_COUNTRY", "false").lower() == "true"

# -------------------------
# Target job titles
# -------------------------
TARGET_TITLES_DATA = [
    "Data Analyst", "Data Engineer", "DevOps Engineer", "Site Reliability Engineer", "SRE",
    "Cloud Engineer", "AWS DevOps Engineer", "Azure DevOps Engineer", "Platform Engineer",
    "Infrastructure Engineer", "Cloud Operations Engineer", "Reliability Engineer",
    "Automation Engineer", "Cloud Consultant", "Build Engineer", "CICD Engineer",
    "Systems Reliability Engineer", "Observability Engineer", "Kubernetes Engineer",
    "DevSecOps Engineer", "Infrastructure Developer", "Platform Reliability Engineer",
    "Automation Specialist",
]

TARGET_TITLES_CYBER = [
    "Cybersecurity Engineer", "Security Engineer", "SOC Analyst", "SOC Analyst III", "Pentester", "GRC Analyst",
    "IAM Analyst", "IAM Engineer", "IAM Administrator", "Cloud Security", "Cybersecurity Analyst",
    "Cyber Security SOC Analyst II", "Incident Response Analyst", "Threat Detection Analyst", "SIEM Analyst",
    "Senior Cybersecurity Analyst", "Security Monitoring Analyst", "Information Security Analyst",
    "Cloud Security Analyst", "Azure Security Analyst", "Identity & Access Specialist", "SailPoint Developer",
    "SailPoint Consultant", "Azure IAM Engineer", "Cloud IAM Analyst", "System Engineer",
    "System Engineer I", "System Engineer II", "System Engineer III",
]

TARGET_TITLES_ORACLE = [
    "Oracle Developer", "OIC Developer", "Oracle Cloud Engineer", "Oracle Integration Cloud",
    "Oracle Fusion Developer", "Oracle HCM", "Oracle ERP", "OIC Consultant", "Oracle Cloud Consultant",
]

# -------------------------
# Email / Sheets config
# -------------------------
EMAIL_SENDER = os.getenv("EMAIL_SENDER")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
EMAIL_RECEIVER_CYBER = os.getenv("EMAIL_RECEIVER_CYBER", "")
EMAIL_RECEIVER_DATA = os.getenv("EMAIL_RECEIVER_DATA", "")
EMAIL_RECEIVER_ORACLE = os.getenv("EMAIL_RECEIVER_ORACLE", "")
GOOGLE_CREDENTIALS = os.getenv("GOOGLE_CREDENTIALS")

SHEET_CYBER = os.getenv("SHEET_CYBER", "Sheet3")
SHEET_DATA = os.getenv("SHEET_DATA", "Sheet4")
SHEET_ORACLE = os.getenv("SHEET_ORACLE", "Sheet5")
WORKBOOK_NAME = os.getenv("WORKBOOK_NAME", "LinkedIn Job Tracker")

# Google Sheets setup
SCOPE = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds_dict = json.loads(GOOGLE_CREDENTIALS) if GOOGLE_CREDENTIALS else {}
CREDS = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, SCOPE)
client = gspread.authorize(CREDS)

# -------------------------
# LinkedIn config
# -------------------------
BASE_URL = "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search"

def make_session() -> requests.Session:
    s = requests.Session()
    retries = Retry(
        total=3, connect=3, read=3,
        backoff_factor=0.6,
        status_forcelist=(429, 500, 502, 503, 504),
        allowed_methods=("GET",),
        raise_on_status=False,
    )
    s.mount("https://", HTTPAdapter(max_retries=retries))
    s.headers.update({
        "User-Agent": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                       "AppleWebKit/537.36 (KHTML, like Gecko) "
                       "Chrome/124.0.0.0 Safari/537.36"),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "en-US,en;q=0.9",
        "Referer": "https://www.linkedin.com/jobs/search/",
        "Cache-Control": "no-cache",
    })
    return s

SESSION = make_session()

# -------------------------
# Locations ‚Äî rotate a slice per run (no utcnow)
# -------------------------
LOCATIONS_US = [
    "New York, NY", "San Francisco Bay Area", "Austin, TX", "Dallas-Fort Worth Metroplex",
    "Chicago, IL", "Seattle, WA", "Atlanta, GA", "Boston, MA", "Los Angeles, CA",
    "Washington, DC-Baltimore Area", "Denver, CO", "Phoenix, AZ", "Charlotte, NC",
    "Kansas City Metropolitan Area", "Philadelphia, PA", "Houston, TX", "Orlando, FL",
    "Minneapolis-St. Paul, MN", "Pittsburgh, PA", "Salt Lake City, UT",
]

def rotating_slice(seq, size, seed: int | None = None):
    """Return a deterministic slice of `seq` of length `size`, rotated by UTC hour."""
    if not seq:
        return []
    if size >= len(seq):
        return list(seq)
    if seed is None:
        seed = datetime.now(timezone.utc).hour  # timezone-aware
    start = seed % len(seq)
    out = seq[start:] + seq[:start]
    return out[:size]

# -------------------------
# Helpers
# -------------------------
HEADER_ROW = ["Job URL", "Title", "Company", "Location", "Category", "Country"]

def parse_recipients(emails_str: str):
    return [e.strip() for e in emails_str.split(",") if e.strip()]

def send_email(subject: str, body: str, to_emails: list[str]):
    if not to_emails:
        return
    if not EMAIL_SENDER or not EMAIL_PASSWORD:
        print("‚ö†Ô∏è EMAIL_SENDER or EMAIL_PASSWORD not set; skipping send.")
        return
    msg = MIMEText(body)
    msg["Subject"] = subject
    msg["From"] = EMAIL_SENDER
    msg["To"] = ", ".join(to_emails)
    with smtplib.SMTP_SSL("smtp.gmail.com", 465) as server:
        server.login(EMAIL_SENDER, EMAIL_PASSWORD)
        server.sendmail(EMAIL_SENDER, to_emails, msg.as_string())

def extract_country(location: str):
    loc = (location or "").lower()
    if "united states" in loc or "usa" in loc:
        return "United States"
    return "Other"

def ensure_header(ws):
    """Ensure row 1 contains the expected header before inserting data at row 2."""
    try:
        first_row = ws.row_values(1)
    except Exception:
        first_row = []
    if first_row != HEADER_ROW:
        if first_row:
            ws.delete_rows(1)
        ws.insert_row(HEADER_ROW, index=1)

def load_sheet(tab_name: str):
    try:
        ws = client.open(WORKBOOK_NAME).worksheet(tab_name)
    except gspread.WorksheetNotFound:
        sh = client.open(WORKBOOK_NAME)
        ws = sh.add_worksheet(title=tab_name, rows=1000, cols=len(HEADER_ROW))
    ensure_header(ws)
    return ws

def preload_urls(ws):
    """Return a set of existing Job URL values (skip header row)."""
    try:
        col = ws.col_values(1)
        return set(col[1:]) if col else set()
    except Exception as e:
        print(f"‚ùå Error loading URLs from {ws.title}: {e}")
        return set()

def mark_job_as_sent(ws, job_url, title, company, location, category, country):
    """Insert newest job at row 2 (keeps header in row 1)."""
    try:
        ensure_header(ws)
        ws.insert_row([job_url, title, company, location, category, country], index=2)
    except Exception as e:
        print(f"‚ùå Error writing to sheet {ws.title}: {e}")

def matches_any(title_lower: str, keywords: list[str]):
    return any(k.lower() in title_lower for k in keywords)

def process_jobs(query_params, keywords, category, expected_country, sent_urls: set, recipients: list[str], ws):
    seen_jobs = set()
    for page_idx in range(MAX_PAGES):
        query_params["start"] = page_idx * 25
        try:
            resp = SESSION.get(BASE_URL, params=query_params, timeout=15)
        except requests.RequestException as e:
            print(f"‚ùå Request error: {e}")
            break

        if resp.status_code != 200 or not resp.text.strip():
            break

        soup = BeautifulSoup(resp.text, "html.parser")
        cards = soup.find_all("li")
        if not cards:
            break

        for card in cards:
            link_tag = card.select_one('[class*="_full-link"]')
            title_tag = card.select_one('[class*="_title"]')
            company_tag = card.select_one('[class*="_subtitle"]')
            location_tag = card.select_one('[class*="_location"]')
            if not (link_tag and title_tag and company_tag):
                continue

            job_url = link_tag["href"].strip().split("?")[0]
            title = title_tag.get_text(strip=True)
            title_lower = title.lower()
            company = company_tag.get_text(strip=True)
            location = location_tag.get_text(strip=True) if location_tag else "Unknown"
            country = extract_country(location)

            # de-dupe across run + sheet
            dedup_key = f"{title_lower}::{company.lower()}"
            if dedup_key in seen_jobs or job_url in sent_urls:
                continue
            seen_jobs.add(dedup_key)

            country_ok = (not ENFORCE_COUNTRY) or (country == expected_country)
            if matches_any(title_lower, keywords) and country_ok:
                email_body = f"{title} at {company} ‚Äî {location}\n{job_url}"
                subject = f"üîî New {category} Job"
                send_email(subject, email_body, recipients)
                mark_job_as_sent(ws, job_url, title, company, location, category, country)
                sent_urls.add(job_url)
                print(f"‚úÖ Sent {category} job: {title}")

def run_category(category_name: str, keywords: list[str], recipients_env: str, sheet_name: str):
    ws = load_sheet(sheet_name)
    sent_urls = preload_urls(ws)
    recipients = parse_recipients(recipients_env)
    if not recipients:
        print(f"‚ö†Ô∏è No recipients configured for {category_name}. Set EMAIL_RECEIVER_* env.")

    # normalize keywords
    cleaned_keywords = [k.strip() for k in keywords if k and k.strip()]

    # rotate a small slice of locations to reduce requests
    locations = rotating_slice(LOCATIONS_US, PER_RUN_LOCATIONS)
    for loc in locations:
        q = {
            "keywords": " OR ".join(cleaned_keywords),
            "location": loc,
            "f_TPR": TIME_WINDOW,
            "sortBy": "DD",
        }
        process_jobs(
            query_params=q,
            keywords=cleaned_keywords,
            category=category_name,
            expected_country="United States",
            sent_urls=sent_urls,
            recipients=recipients,
            ws=ws,
        )

# -------------------------
# Orchestration
# -------------------------
def check_new_jobs():
    run_category("Cybersecurity", TARGET_TITLES_CYBER, EMAIL_RECEIVER_CYBER, SHEET_CYBER)
    run_category("DevOps", TARGET_TITLES_DATA, EMAIL_RECEIVER_DATA, SHEET_DATA)
    run_category("Oracle", TARGET_TITLES_ORACLE, EMAIL_RECEIVER_ORACLE, SHEET_ORACLE)

# -------------------------
# Routes
# -------------------------
@app.route("/", methods=["GET"])
def health():
    # Fast health check (no network)
    return "OK"

@app.route("/run", methods=["POST", "GET"])
def run():
    try:
        check_new_jobs()
        return "‚úÖ Scrape complete"
    except OSError as e:
        # e.g., [Errno 101] Network is unreachable
        return f"‚ùå Network error during scrape: {e}", 503
    except Exception as e:
        return f"‚ùå Unexpected error: {e}", 500

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    app.run(host="0.0.0.0", port=port)
